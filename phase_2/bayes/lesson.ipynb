{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Bayesian Reasoning"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-02-02T21:24:51.675422Z", "start_time": "2021-02-02T21:24:50.910157Z"}}, "outputs": [], "source": ["import sys\n", "import os\n", "import numpy as np\n", "from matplotlib import pyplot as plt\n", "import seaborn as sns\n", "grandparent_directory = os.path.join(os.pardir, os.pardir)\n", "module_path = os.path.abspath(grandparent_directory)\n", "sys.path.append(module_path)\n", "from src.piApprox import pi_approx\n", "import src.monty_hall as mh\n", "\n", "%matplotlib inline"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## A Philosophical Note\n", "\n", "Philosophers wonder about the best way to understand what probabilities are. The main division is between those who want to understand probabilities _objectively_ and those who want to understand probabilities _subjectively_.\n", "\n", "### Historical Relevance\n", "In the early twentieth century, the quantum theory being developed by physicists was saying that the location (etc.) of a particle could be represented by a probabilistic wave function that gave probabilities for the particle to be in one place rather than another. And this question of how to understand these probabilities reared its head. Albert Einstein argued that they could only be interpreted subjectively, but the dominant interpretation today is that there is a kind of indeterminacy in the universe itself.\n", "\n", "### Objective Probability\n", "The paradigmatic theory of _objective_ probability is frequentism, which says that probabilities are a measure of the long-run behvior of physical systems. To say that a die has a 1/6 chance of coming up \"6\" when tossed, for example, is to say that, in the long run as the number of tosses increases without bound, the number of \"6\"s rolled will constitute one sixth of all tosses.\n", "\n", "On this point of view, **we cannot speak meaningfully of the probability of a single event**. Once a die has been rolled, there is no non-trivial probability of its having come up \"6\" or not. Either it did (in which case the probability is 1) or it did not (in which case the probability is 0).\n", "\n", "Similarly, **we cannot speak meaningfully of the probability of a parameter having a certain value, or of a hypothesis being true**. The frequentist will reject the idea of a (meaningful) probability of a die being unfairly weighted. Either it is or it is not.\n", "\n", "\n", "### Subjective Probability\n", "The paradigmatic theory of _subjective_ probability is Bayesianism, which says that probabilities are better understood as rational _degrees of belief_. The standard of rationality is necessary here to assure that these degrees of belief will conform to the probability calculus.\n", "\n", "If probabilities are degrees of belief, then it _does_ make sense to apply them to parameters or to hypotheses. The probability of a die being unfairly weighted would simply represent what it would be rational to believe about the die with respect to its being weighted or not.\n", "\n", "Now: Crucially, what it is rational to believe about the die with respect to its being weighted or not _is a function of what we know about the die!_\n", "\n", "In particular, if we gain the evidence (or knowledge) that the die has been rolled 100 times and come up \"5\" 90 times, then this would have (or, rather, *ought, rationally, to have*) a significant impact on our degree of belief with respect to the weightedness of the die. This is the sort of idea that Thomas Bayes had.\n", "\n", "## Review\n", "\n", "__Prior p(H):__ Our prior reflects what we know about the value of some parameter before seeing data.  This could refer to previous trials and distributions.\n", "\n", "__Likelihood p(D|H)__: what is the plausibility that our data is observed, given our prior?\n", "\n", "__Posterior p(H|D):__ This is result of the Bayesian analysis and reflects all that we know about a problem (given our data and model).\n", "\n", "__Evidence p(D):__ Evidence is the probability of observing the data averaged over all the possible values the parameters can take. Also knowns as the noramlziing factor. The normalising constant makes sure that the resulting posterior distribution is a true probability distribution by ensuring that the sum of the distribution is equal to 1."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## A Famous Example\n", "\n", "Suppose some rare disease affects 1 in 100,000 people. There is a test for it, though it is imperfect: 5% of the people who have the disease will test negative and 4% of the people who don't have the disease will test positive for it. You take the test and test positive. Before the test the probability that you had the disease was only 1 in 100,000. But now, with this new information of the positive test, how should you judge the probability that you have the disease?\n", "\n", "We can use Bayes's Theorem:\n", "\n", "$\\huge P(H | D) = \\frac{P(D | H)P(H)}{P(D)}$.\n", "\n", "What are $H$ and $D$ in this case?\n", "\n", "To calculate the denominator, we'll need to make use of the **Rule of Total Evidence**: <br/><br/>\n", "$\\large P(D) = P(D | H_1)P(H_1) + ... + P(D | H_n)P(H_n)$\n", "\n", "In our case, there are only two possibilities: Either I have the disease or I do not."]}, {"cell_type": "markdown", "metadata": {}, "source": ["It is often times helpful to rewrite the equations so the terms are specific to the situation. In this case it would look like this...\n", "\n", "$P(Disease|Positive) = \\frac{P(Positive | Disease)P(Disease)}{P(Positive)}$.\n", "\n", "\n", "$ P(Positive) = P(Positive | Disease)P(Disease) + P(Positive | No Disease)P(No Disease)$"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-02-02T21:58:33.845167Z", "start_time": "2021-02-02T21:58:33.841620Z"}}, "outputs": [], "source": ["(0.95 * 0.00001) / (0.95 * 0.00001 + 0.04 * 0.99999)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The probability that I have the disease is still less than 1 in 4000!\n", "\n", "## The Monty Hall Problem\n", "\n", "Bayesian reasoning applies naturally and neatly to the famous Monty Hall Problem.\n", "\n", "The situation is this: Monty Hall, classic and original host of the TV game show \"Let's Make a Deal\", has told you, the contestant, that there is some fantastic prize behind one of three doors. Suppose, without loss of generality, that you select Door \\#1.\n", "\n", "Now here's where the story gets interesting. Hall then shows you that the prize is NOT behind one of the other two doors. Let's suppose, again without loss of generality he opens Door \\#2.\n", "\n", "Note a few things at this point:\n", "\n", "1. Hall will never show you what's behind the door you selected.\n", "2. Hall will never show you where the good prize is.\n", "3. \\#1 and \\#2 notwithstanding, Hall will always be able to show you what's behind one of the doors without revealing where the prize is.\n", "\n", "Then Hall asks you if you'd like to *switch* your pick to the remaining door.\n", "\n", "The question is: Do you have any reason to switch? Or do you have any reason to stick with your original choice?\n", "\n", "It is natural to reason in the following way: Either the prize is behind Door \\#1, the one I picked, or it is behind Door \\#3. Clearly, the fact that Hall opened Door \\#2 could not have had any effect on the location of the prize, so there is no reason to prefer Door \\#1 or Door \\#3. So the probability that the prize is behind either of the two remaining doors is 50%.\n", "\n", "But this reasoning is wrong! The fallaciousness of this reasoning was pointed out in a magazine column in the 1980s, although the writer of the column received much criticism from many \"experts\" who were arguing that the reasoning was perfectly sound. (There's a nice article about the history here: https://priceonomics.com/the-time-everyone-corrected-the-worlds-smartest/.)\n", "\n", "The truth is that you ought to switch! The truth is that, while there is only 1 chance in 3 that the door you originally selected has the prize, there are 2 chances in 3 that the other door has the prize.\n", "\n", "Let's see if we can proceed through this puzzle in Bayesian terms.\n", "\n", "### Posterior Probability that the Prize Is Behind Your Door\n", "Let's calculate the posterior probability that the prize is behind Door \\#1, given the evidence that Hall shows you that it is not behind Door \\#2:\n", "\n", "What is the *prior* probability that the prize is behind Door \\#1?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-03-31T21:36:28.741577Z", "start_time": "2021-03-31T21:36:28.738287Z"}}, "outputs": [], "source": ["prior_1 = 1/3\n", "prior_1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now let's consider the likelihood of the evidence: What is the probability that Hall would show you that it is not behind Door \\#2, given the hypothesis that the prize is behind Door \\#1?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-03-31T21:37:06.289760Z", "start_time": "2021-03-31T21:37:06.286230Z"}, "scrolled": true}, "outputs": [], "source": ["likelihood_1 = 0.5\n", "likelihood_1"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Finally, let's calculate the probability of the evidence itself:\n", "\n", "There are three salient hypotheses to consider:\n", "\n", "- $H_1$: The prize is behind Door \\#1.\n", "- $H_2$: The prize is behind Door \\#2.\n", "- $H_3$: The prize is behind Door \\#3.\n", "\n", "And our evidence is:\n", "\n", "- $D$: Hall shows you that the prize is not behind Door \\#2.\n", "\n", "We can calculate the probability as follows:\n", "\n", "$P(D) = P(D | H_1)\\times P(H_1) + P(D | H_2)\\times P(H_2) + P(D | H_3)\\times P(H_3)$.\n", "\n", "We've already made the calculation for the first term:\n", "\n", "$P(D | H_1)\\times P(H_1) = \\frac{1}{2}\\times\\frac{1}{3} = \\frac{1}{6}$.\n", "\n", "Now:\n", "\n", "The probability that Hall would show you Door \\#2, given that the prize is behind Door \\#2, is *zero*. (This is by the rules of the game.)\n", "\n", "The probability that Hall would show you Door \\#2, given that the prize is behind Door \\#3, is *one*. (Here Hall's hand would be forced, since he can, by the rules, show you neither the door that you chose (\\#1) nor the door with the prize (\\#3).)\n", "\n", "So we have:\n", "\n", "$P(D) = \\frac{1}{2}\\times\\frac{1}{3} + (0)\\times\\frac{1}{3} + (1)\\times\\frac{1}{3} = \\frac{1}{2}$.\n", "\n", "We are finally in a position to calculate the posterior! We have:\n", "\n", "$\\large P(H_1 | D) = \\frac{P(D | H_1)\\times P(H)}{P(D)} = \\frac{1 / 6}{1 / 2} = \\frac{1}{3}$.\n", "\n", "That is, our updated probability that the prize is behind Door \\#1 is just the same as the prior. It's still just $\\frac{1}{3}$.\n", "\n", "### Posterior Probability that the Prize Is Behind the Other Door\n", "\n", "The posterior probability that the prize is behind Door \\#3, given the evidence that Hall has shown you what's behind Door \\#2, ought to work out to $\\frac{2}{3}$. Let's verify this:\n", "\n", "What is the *prior* probability that the prize is behind Door \\#3?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-03-31T21:41:08.515215Z", "start_time": "2021-03-31T21:41:08.511679Z"}}, "outputs": [], "source": ["prior_3 = 1/3\n", "prior_3"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Now the likelihood: What's the probability that Hall would show you Door \\#2, given that the prize is behind Door \\#3?"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-03-31T21:41:18.471028Z", "start_time": "2021-03-31T21:41:18.467872Z"}}, "outputs": [], "source": ["likelihood_3 = 1\n", "likelihood_3"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We've already made our calculation of the evidence. From before we had:\n", "\n", "$P(D) = \\frac{1}{2}\\times\\frac{1}{3} + (0)\\times\\frac{1}{3} + (1)\\times\\frac{1}{3} = \\frac{1}{2}$.\n", "\n", "So now we are in a position to calculate the posterior probability that the prize is behind Door \\#3. We have:\n", "\n", "$\\large P(H_3 | D) = \\frac{P(D | H_3)\\times P(H)}{P(D)} = \\frac{1 / 3}{1 / 2} = \\frac{2}{3}$.\n", "\n", "Given that Hall shows us what's behind Door \\#2, we should now update our degree of belief that the prize is behind Door \\#3 to $\\frac{2}{3}$!\n", "\n", "### Let's use `monty_hall.py`!"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-03-31T21:42:51.373637Z", "start_time": "2021-03-31T21:42:51.273937Z"}}, "outputs": [], "source": ["mh.play_mh()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-02-02T22:09:24.149187Z", "start_time": "2021-02-02T22:09:24.145469Z"}}, "outputs": [], "source": ["mh.stats_mh()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-02-02T22:09:29.160871Z", "start_time": "2021-02-02T22:09:25.603416Z"}}, "outputs": [], "source": ["swapping = []\n", "not_swapping = []\n", "for _ in range(100000):\n", "    swapping.append(mh.stats_mh(swap=True))\n", "    not_swapping.append(mh.stats_mh(swap=False))\n", "print(sum(swapping) / 100000)\n", "print(sum(not_swapping) / 100000)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["# Bayesian Statistics"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Puppy Questions\n", "\n", "Thomas wants to get a new puppy \ud83d\udc15 \ud83d\udc36 \ud83d\udc29 \n", "\n", "\n", "<img src=\"https://media.giphy.com/media/rD8R00QOKwfxC/giphy.gif\" />\n", "\n", "He can choose to get his new puppy either from the pet store or the pound. The probability of him going to the pet store is $0.2$. \n", "\n", "He can choose to get either a big, medium or small puppy.\n", "\n", "If he goes to the pet store, the probability of him getting a small puppy is $0.6$. The probability of him getting a medium puppy is $0.3$, and the probability of him getting a large puppy is $0.1$.\n", "\n", "If he goes to the pound, the probability of him getting a small puppy is $0.1$. The probability of him getting a medium puppy is $0.35$, and the probability of him getting a large puppy is $0.55$.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 1) What is the probability of Thomas getting a small puppy?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here.  Write out your process in addition to your final numeric answer."]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### 2) Given that he got a large puppy, what is the probability that Thomas went to the pet store?"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here.  Write out your process in addition to your final numeric answer."]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Med Question\n", "\n", "A medical test is designed to diagnose a certain disease. The test has a false positive rate of 10%, meaning that 10% of people without the disease will get a positive test result. The test has a false negative rate of 2%, meaning that 2% of people with the disease will get a negative result. Only 1% of the population has this disease.\n", "\n", "\n", "#### 3) If a patient receives a positive test result, what is the probability that they actually have the disease? Show how you arrive at your answer."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your answer here.  Write out your process in addition to your final numeric answer."]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "beuY1nFFpbcF"}, "source": ["# Bayesian Inference"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "SA-eNhIfpbce"}, "source": ["## Flatiron IQ Scores\n", "\n", "We have a prior belief, based on previous studies, that the IQ of Flatiron Students is normally distributed with a mean IQ of 100 and a standard deviation of 10."]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-02-02T22:17:18.912422Z", "start_time": "2021-02-02T22:17:18.729263Z"}, "colab": {}, "colab_type": "code", "id": "O39Sb2WLpbcf"}, "outputs": [], "source": ["prior_distribution = np.random.normal(100, 10, 1000)\n", "plt.hist(prior_distribution);"]}, {"cell_type": "markdown", "metadata": {"colab_type": "text", "id": "LwcQkHPApbck"}, "source": ["We then take a random sample of student IQs. Our sample is normally distributed with a mean of 115 and standard deviation of 7.5. From this, we can construct a posterior distribution. \n", "\n", "In order to do this, we update our prior by updating the mean and variance each observation.\n", "\n", "The equations for our updated prior mean and variance are:\n", "\n", "$$Updated\\ Prior\\ Mean = \\frac{\\sigma^2_{observed}\\mu + \\sigma_{prior}^2x}{\\sigma_{observed}^2 + \\sigma_{prior}^2}$$\n", "\n", "$$Updated\\ Prior\\ Variance = \\frac{\\sigma_{observed}^2\\sigma_{prior}^2}{\\sigma_{observed}^2 + \\sigma_{prior}^2}$$"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-02-02T22:50:41.675255Z", "start_time": "2021-02-02T22:50:41.345202Z"}}, "outputs": [], "source": ["def update_prior(prior, observed):\n", "    means = [prior.mean()] * len(observed)\n", "    variations = [prior.var()] * len(observed)\n", "    for i in range(len(observed)):\n", "        means[i] = (variations[i]*observed[i] + observed.var(ddof=i)*means[i] )/(variations[i]+observed.var(ddof=i))\n", "        variations[i] = ((variations[i]*observed.var(ddof=i))/(variations[i]+observed.var(ddof=i)))\n", "        \n", "    posterior = np.random.normal(np.mean(means), np.mean(variations)**.5, 1000)\n", "    \n", "    return posterior\n", "\n", "prior = np.random.normal(100, 10, 1000)\n", "observed = np.random.normal(115, 7.5, 1000)\n", "posterior = update_prior(prior, observed)\n", "\n", "plt.hist(prior, label='prior', alpha=.6)\n", "plt.hist(observed, label='observed', alpha = 0.6)\n", "plt.hist(posterior,label='posterior', alpha = 0.6)\n", "plt.legend()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-02-02T22:46:24.186310Z", "start_time": "2021-02-02T22:46:24.183394Z"}}, "outputs": [], "source": ["def subplot_map(iteration, number_of_columns):\n", "    return iteration//number_of_columns, iteration%number_of_columns"]}, {"cell_type": "code", "execution_count": null, "metadata": {"ExecuteTime": {"end_time": "2021-02-02T22:51:13.782475Z", "start_time": "2021-02-02T22:51:09.106861Z"}}, "outputs": [], "source": ["fig, axes = plt.subplots(5,5, figsize=(10,5))\n", "population = np.random.normal(115, 15, 10000)\n", "prior = np.random.normal(100, 10, 1000)\n", "for i in range(25):\n", "    observed = np.random.choice(population, 1000)\n", "    if i == 0:\n", "        posterior = update_prior(prior, observed)\n", "    else:\n", "        posterior = update_prior(posterior, observed)\n", "    row, column = subplot_map(i, 5)\n", "    axes[row,column].hist(prior, label='prior', alpha=.6)\n", "    axes[row,column].hist(observed, label='observed', alpha = 0.6)\n", "    axes[row,column].hist(posterior,label='posterior', alpha = 0.6)\n", "handles, labels = axes[row,column].get_legend_handles_labels()\n", "fig.legend(handles, labels, loc='center right');"]}], "metadata": {"colab": {"collapsed_sections": [], "name": "Python Bayesian Tutorial.ipynb", "provenance": [], "version": "0.3.2"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}, "toc": {"base_numbering": 1, "nav_menu": {}, "number_sections": false, "sideBar": true, "skip_h1_title": false, "title_cell": "Table of Contents", "title_sidebar": "Contents", "toc_cell": false, "toc_position": {}, "toc_section_display": true, "toc_window_display": false}}, "nbformat": 4, "nbformat_minor": 2}